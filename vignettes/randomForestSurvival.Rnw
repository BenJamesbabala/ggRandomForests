\documentclass[nojss]{jss}

%\usepackage{setspace}
% \usepackage[sc]{mathpazo}
\usepackage{amsmath}
% %\usepackage{geometry} 
% %\geometry{verbose, tmargin = 1.25cm, bmargin = 1.25cm, lmargin = 1.25cm, rmargin = 1.25cm}
% \setcounter{secnumdepth}{2}
% \setcounter{tocdepth}{2}
\usepackage{longtable}
\usepackage{colortbl, xcolor}
\usepackage{booktabs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{survivalRandomForest}
%\VignetteIndexEntry{Random Forests for Survival ggRandomForests packages}                     
%\VignetteKeywords{random forest, survival, VIMP, minimal depth}                                  
%\VignetteDepends{ggRandomForests}                   
%\VignettePackage{ggRandomForests} 

%% almost as usual
\author{John Ehrlinger 
\and Eugene H. Blackstone\\Cleveland Clinic}

\title{\pkg{ggRandomForests}: Survival with Random Forests}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Ehrlinger et.\ al.} %% comma-separated
\Plaintitle{ggRandomForests: Random Forests for Survival} %% without formatting
\Shorttitle{Random Forests for Survival}

%% an abstract and keywords
\Abstract{ 
Random Forests~\citep{Breiman:2001} (RF) are a fully non-parametric statistical method requiring no distributional assumptions on covariate relation to the response. RF are a robust, nonlinear technique that optimizes predictive accuracy by fitting an ensemble of trees to stabilize model estimates. Random Forests for survival~\citep{Ishwaran:2007a, Ishwaran:2008} (RF-S) are an extension of Breiman's RF techniques to survival settings, allowing efficient non-parametric analysis of time to event data. The \pkg{randomForestSRC} package~\citep{Ishwaran:RFSRC:2014} is a unified treatment of Breiman's random forests for survival, regression and classification problems.

Predictive accuracy make RF an attractive alternative to parametric models, though complexity and interpretability of the forest hinder wider application of the method. We introduce the \pkg{ggRandomForests} package, tools for creating and plotting data structures to visually understand random forest models grown in \proglang{R} with the \pkg{randomForestSRC} package. The \pkg{ggRandomForests} package is structured to extract intermediate data objects from \pkg{randomForestSRC} objects and generate figures using the \pkg{ggplot2}~\citep{Wickham:2009} graphics package.

This document is formatted as a tutorial for using the \pkg{randomForestSRC} for building random forests for survival and \pkg{ggRandomForests} package for investigating how the forest is constructed. This tutorial uses the Primary Biliary Cirrhosis (PBC) Data from the Mayo Clinic~\citep{fleming:1991} available in the \pkg{randomForestSRC} package. We use Variable Importance measure (VIMP)~\citep{Breiman:2001} as well as Minimal Depth~\citep{Ishwaran:2010}, a property derived from the construction of each tree within the forest, to assess the impact of variables on forest prediction. We will also demonstrate the use of variable dependence plots~\citep{Friedman:2000} to aid interpretation RF results in different response settings. We also will investigate interactions between covariates to demonstrate the strength of the Random Forest method in survival settings.
}
\Keywords{random forest, survival, VIMP, minimal depth, \proglang{R}, \pkg{randomForestSRC}}
\Plainkeywords{random forest, survival, VIMP, minimal depth, R, randomForestSRC}
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
John Ehrlinger\\
Quantitative Health Sciences\\
Lerner Research Institute\\
Cleveland Clinic\\
9500 Euclid Ave\\
Cleveland, Ohio 44195\\
% Telephone: + 41/0/44634-4643 \\
% Fax: + 41/0/44634-4386 \\
E-mail: \email{john.ehrlinger@gmail.com}\\
URL: \url{http://www.lerner.ccf.org/qhs/people/ehrlinj/}
}

%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: + 43/1/31336-5053
%% Fax: + 43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<setup, include = FALSE, cache = FALSE, echo = FALSE>>= 
library(knitr)
knitr::render_sweave() 
# set global chunk options for knitr. These can be changed in the header for each individual R code chunk
opts_chunk$set(fig.path = 'figure/rfs-', 
               fig.align = 'center', 
               fig.pos = "!htpb", 
               fig.show = 'hold', 
               fig.height = 3, 
               fig.width = 4, 
               size = 'footnotesize', 
               prompt = TRUE, 
               highlight = FALSE, 
               comment = NA, 
               echo = FALSE, results = FALSE, message = FALSE, warning = FALSE, 
               error = FALSE, dev = 'pdf', prompt = TRUE)

# Setup the R environment
options(object.size = Inf, expressions = 100000, memory = Inf, 
        replace.assign = TRUE, width = 90, prompt = "R> ")

#################
# Load_packages #
#################
library(ggplot2) # Graphics engine for generating all types of plots

library(dplyr) # Better data manipulations
library(reshape2)
library(parallel)

library(ggRandomForests)

# Analysis packages.
library(randomForestSRC) 
library(RColorBrewer)

library(xtable)

options(mc.cores = 1, rf.cores = 1)

#########################################################################
# Default computation settings
#########################################################################
theme_set(theme_bw())
event.marks <- c(1, 4)
event.labels <- c(FALSE, TRUE)
strCol <- brewer.pal(3, "Set1")
strCol <- strCol[c(2, 1, 3)]
alpha <- .3
## Set the event/censor marks. Want open circle for censored, and 
## x for events 
event.marks = c(1, 4)
event.labels = c(FALSE, TRUE)
strCol <- brewer.pal(3, "Set1")
strCol <- c(strCol[2], strCol[1])
@

\begin{document}
% -----------------------------------------------------
\section*{About this document}\addcontentsline{toc}{section}{About this document}
% -----------------------------------------------------

This document is a package vignette for the \pkg{ggRandomForests} (\url{http://CRAN.R-project.org/package=ggRandomForests}) package for ``Visually Exploring Random Forests''. \pkg{ggRandomForests} will help uncover variable associations in random forest models. The package is designed for use with the \pkg{randomForestSRC} (\url{http://CRAN.R-project.org/package=randomForestSRC}) package~\citep{Ishwaran:RFSRC:2014} for survival, regression and classification forests and uses the \pkg{ggplot2}(\url{http://CRAN.R-project.org/package=ggplot2}) package~\citep{Wickham:2009} for plotting diagnostic and variable association results. \pkg{ggRandomForests} is  structured to extract data objects from \pkg{randomForestSRC} objects and provides S3 functions for printing and plotting these objects.

The vignette is a tutorial for using the \pkg{ggRandomForests} package with the \pkg{randomForestSRC} package for building and post-processing a survival random forest. In this tutorial, we explore a random forest for survival model for the primary biliary cirrhosis (PBC) of the liver data set~\citep{fleming:1991}, available in the \pkg{randomForestSRC} package. We grow a survival random forest and demonstrate how \pkg{ggRandomForests} can be used when determining variable associations, interactions and how the survival response depends on predictive variables within the model. The tutorial demonstrates the design and usage of many of \pkg{ggRandomForests} functions and features how to modify and customize the resulting ggplot2 graphic objects along the way.

The latest version of this vignette is available within the \pkg{ggRandomForests} package on the Compreshensive R Archive Network (CRAN) (\url{http://cran.r-project.org}). Once the package has been installed, the vignette can be viewed directly from within \proglang{R} with the following command:
<<vignette, eval=FALSE, echo=TRUE>>=
vignette("randomForestSurvival", package="ggRandomForests")
@

A development version of the \pkg{ggRandomForests} package is also available on Github (\url{https://github.com}). We invite comments, feature requests and bug reports for this package at \url{https://github.com/ehrlinger/ggRandomForests}.

% -----------------------------------------------------
\section{Introduction} \label{S:introduction}
% -----------------------------------------------------

Random Forests~\citep{Breiman:2001} (RF) are a fully non-parametric statistical method which requires no distributional assumptions on covariate relation to the response. RF is a robust, nonlinear technique that optimizes predictive accuracy by fitting an ensemble of trees to stabilize model estimates. Random Survival Forests (RSF)~\citep{Ishwaran:2007a,Ishwaran:2008} are an extension of Breiman's RF techniques to survival settings, allowing efficient non-parametric analysis of time to event data. The \pkg{randomForestSRC} (\url{http://CRAN.R-project.org/package=ggRandomForests}) package~\citep{Ishwaran:RFSRC:2014} is a unified treatment of Breiman's random forests for survival, regression and classification problems.

Predictive accuracy make RF an attractive alternative to parametric models, though complexity and interpretability of the forest hinder wider application of the method. We introduce the \pkg{ggRandomForests} (\url{http://CRAN.R-project.org/package=ggRandomForests}) package for visually exploring random forest models. The \pkg{ggRandomForests} package is structured to extract intermediate data objects from \pkg{randomForestSRC} objects and generate figures using the \pkg{ggplot2} (\url{http://CRAN.R-project.org/package=ggplot2}) graphics package~\citep{Wickham:2009}.

Many of the figures created by the \pkg{ggRandomForests} package are also available directly from within the \pkg{randomForestSRC} package. However \pkg{ggRandomForests} offers the following advantages:
\begin{itemize}
\item Separation of data and figures: \pkg{ggRandomForests} contains functions that  operate on either the \code{randomForestSRC::rfsrc} forest object directly, or on the output from \pkg{randomForestSRC} post processing functions (i.e. \code{plot.variable}, \code{var.select}, \code{find.interaction}) to generate intermediate \pkg{ggRandomForests} data objects. S3 functions are provide to further process these objects and plot results using the \pkg{ggplot2} graphics package. Alternatively, users can use these data objects for their own custom plotting or analysis operations.  

\item Each data object/figure is a single, self contained object. This allows simple modification and manipulation of the data or \pkg{ggplot2} objects to meet users specific needs and requirements. 

\item The use of \pkg{ggplot2} for plotting. We chose to use the \pkg{ggplot2} package for our figures to allow users flexibility in modifying the figures to their liking. Each S3 plot function returns either a single \pkg{ggplot2} object, or a \code{list} of \pkg{ggplot2} objects, allowing users to use additional \pkg{ggplot2} functions or themes to modify and customize the figures to their liking.  
\end{itemize}

This document is formatted as a tutorial for using the \pkg{randomForestSRC} package for building and post-processing random survival forest models with the \pkg{ggRandomForests} package for investigating how the forest is constructed. In this tutorial, we will investigate the primary biliary cirrhosis (PBC) of the liver data set~\citep{fleming:1991}, available in the \pkg{randomForestSRC} package. We present the data in Section~\ref{S:data} before building a random survival forest in Section~\ref{S:rfsrcGrow}. 

Random forests are not parsimonious, but use all variables available in the construction of a response predictor. We demonstrate a random forest variable selection process (Section~\ref{S:variableselection}) using the Variable Importance measure (VIMP)~\citep{Breiman:2001} in Section~\ref{S:vimp} as well as Minimal Depth~\citep{Ishwaran:2010} in Section~\ref{S:minimalDepth}. Minimal depth is a property derived from the construction of each tree within the forest, which we use to assess the impact of variables on forest prediction. 

Once we have an idea of which variables the forest is using for prediction, we will use variable dependence plots~\citep{Friedman:2000} (Section~\ref{S:dependence}) to understand how a variable is related to the response. Marginal variable dependence (Section~\ref{S:variabledependence}) plots give us an idea of the overall trend of a variable/response relation, while partial dependence plots (Section~\ref{S:partialdependence}) show us a risk adjusted relation. These figures often show strongly non-linear variable/response relations that are not easily obtained through a parametric approach. We are also interested in examining variable interactions (Section~\ref{S:interactions}) within the forest model. Using a minimal depth approach, we can quantify how closely variables are related within the forest, and generate marginal dependence and partial dependence (risk adjusted) conditioning plots (coplots)~\citep{chambers:1992,cleveland:1993} to examine these interactions graphically  (Section~\ref{S:coplots}).

\section{Data Summary: Primary Biliary Cirrhosis (PBC) Data}\label{S:data}

Data was obtained from a Mayo Clinic randomized trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and 1984. A total of 424 PBC patients, referred to Mayo Clinic during that ten-year interval, met eligibility criteria for the randomized placebo controlled trial of the drug D-penicillamine. The first 312 cases in the data set participated in the randomized trial and contain largely complete data. The data is described in~\cite{fleming:1991} in Chapter 0.2 and Chapter 4.4. We will use the \code{pbc} data set transcribed from Appendix D, which is included in the \pkg{randomForestSRC} package.

<<datastep, echo=TRUE>>= 
data(pbc, package = "randomForestSRC")
@

<<data-clean>>=
## Set modes correctly. For binary variables: transform to logical
## Check for range of 0, 1
## There is probably a better way to do this.
for(ind in 1:dim(pbc)[2]){
  if(!is.factor(pbc[, ind])){
    if(length(unique(pbc[which(!is.na(pbc[, ind])), ind]))<= 2) {
      if(sum(range(pbc[, ind], na.rm = TRUE) ==  c(0, 1)) ==  2){
        pbc[, ind] <- as.logical(pbc[, ind])
        }
  }
 }else{
  if(length(unique(pbc[which(!is.na(pbc[, ind])), ind]))<= 2) {
   if(sum(sort(unique(pbc[, ind])) ==  c(0, 1)) ==  2){
    pbc[, ind] <- as.logical(pbc[, ind])
   }
   if(sum(sort(unique(pbc[, ind])) ==  c(FALSE, TRUE)) ==  2){
    pbc[, ind] <- as.logical(pbc[, ind])
   }
  }
 }
 if(!is.logical(pbc[, ind]) & 
    length(unique(pbc[which(!is.na(pbc[, ind])), ind]))<= 5) {
  pbc[, ind] <- factor(pbc[, ind])
 }
}
# Convert age to years
pbc$age <- pbc$age/364.24
pbc$years <- pbc$days/364.24
pbc <- pbc %>% select(-days)
pbc$treatment <- as.numeric(pbc$treatment)
pbc$treatment[which(pbc$treatment==1)] <- "DPCA"
pbc$treatment[which(pbc$treatment==2)] <- "placebo"
pbc$treatment <- factor(pbc$treatment)

cls <- sapply(pbc, class) 

labels <- c("event indicator (F=censor, T=death)", 
            "Treament (DPCA, Placebo)", 
            "age in years", 
            "Female", 
            "Asictes", 
            "Hepatomegaly", 
            "Spiders", 
            "Edema", 
            "serum bilirubin (mg/dl)", 
            "serum cholesterol (mg/dl)", 
            "albumin (gm/dl)", 
            "urine copper (ug/day)", 
            "alkaline phosphatase (U/liter)", 
            "SGOT (U/ml)", 
            "triglicerides (mg/dl)", 
            "platelets per cubic ml/1000", 
            "prothrombin time (sec)", 
            "histologic stage", 
            "survival time (years)")

dta.labs <- data.frame(cbind(names = colnames(pbc), label = labels, type = cls))

st.labs <- as.character(dta.labs$label)
names(st.labs) <- rownames(dta.labs)
@

For our analysis, we will do some data manipulations for formating results. Since the data contains about 12 years of follow up, we prefer using \code{years} instead of \code{days} survival. We also convert the \code{age} variable to years, and the \code{treatment} variable to a factor containing levels of \code{c("DPCA", "placebo")}. We outline the variable names, type and description in Table~\ref{T:dataLabs}.

<<dta-table, results = "asis">>= 
rws <- seq(1, (nrow(dta.labs)), by = 2)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

print(xtable(dta.labs %>% select(-names), 
             caption = "PBC Data field descriptions", 
             label = "T:dataLabs", 
             digits = 3), 
      size = 'footnotesize', # fontsize
      booktabs = TRUE, 
      add.to.row = list(pos = as.list(rws), command = col), 
      command =  c('\\toprule' , 
                   '\\midrule' , 
                   '\\bottomrule ')
      )
@

\subsection{Exploratory Data Analysis}\label{S:eda}

It is good practice to view your data before beginning an analysis, what~\cite{Tukey:1977} refers to as Exploratory Data Analysis (EDA). To facilitate this, we use \pkg{ggplot2} figures with the \code{facet_wrap} command to create two sets of panel plots, one for categorical variables using histograms (Figure~\ref{fig:categoricalEDA}), and another of scatter plots for continuous variables (Figure~\ref{fig:continuousEDA}). Each variable is plotted along a selected continuous variable on the X-axis, in this case the length of follow up (survival time in \code{years}). These figures help to find outliers, missing values and other data anomalies within each variable before getting deep into the analysis.

<<categoricalEDA, fig.cap="Categorical variable EDA plots. Bars indicate counts within 1 year of followup for each categorical variable. Bars are colored according to the class membership within each variable. Missing values are colored dark grey.", fig.width=7>>=
# Use reshape2::melt to transform the data into long format.
cnt <- c(which(cls == "numeric" ), which(cls == "integer"))
fct <- setdiff(1:ncol(pbc), cnt)
fct <- c(fct, which(colnames(pbc)=="years"))
dta <- melt(pbc[,fct], id.vars="years")

# plot panels for each covariate colored by the logical chas variable.
ggplot(dta, aes(x=years, fill=value))+
  geom_histogram(color="black", binwidth=1)+
  labs(y="", x=st.labs["years"]) +
#  scale_fill_brewer(na.value = "grey50" )+
  facet_wrap(~variable, scales="free_y", nrow=2)+
  theme(legend.position="none")
@


<<continuousEDA, fig.cap="Continuous variable EDA plots. Points indicate variable value against the follow up time in years. Points are colored according to the death event in the  \\code{status} variable. Missing values are indicated by the rug marks along the X-axis", fig.width=7, fig.height=4>>=
# Use reshape2::melt to transform the data into long format.
cnt <- c(cnt, which(colnames(pbc)=="status"))
dta <- melt(pbc[,cnt], id.vars=c("years", "status"))

# plot panels for each covariate colored by the logical chas variable.
ggplot(dta, aes(x=years, y=value, color=status, shape=status))+
  geom_point(alpha=.3)+
  geom_rug(data=dta[which(is.na(dta$value)),], color="grey50")+
  labs(y="", x=st.labs["years"], color="Death", shape="Death") +
  scale_color_manual(values=strCol) +
  scale_shape_manual(values=event.marks)+
  facet_wrap(~variable, scales="free_y", ncol=4)+
  theme(legend.position=c(.8,.2))
@

In categorical EDA plots (Figure~\ref{fig:categoricalEDA}) we are looking for patterns of missing data. We often use surgical date for our X-axis variable to look for periods of low enrollment. The variable was not available in this data set, so we used follow up time (\code{years}) instead. Another good choice may have been to use the \code{age} variable.

In continuous EDA plots (Figure~\ref{fig:continuousEDA}) we look for missingness and extreme values as in the \code{trig} variable. For survival, we color and shape the points corresponds to the censoring indicator (\code{status} variable in Figure~\ref{fig:categoricalEDA}), red x indicates an event, and a blue circle indicates a censored observation.

<<missing, results="asis">>=
pbc.trial <- pbc[-which(is.na(pbc$treatment)),]
st <- apply(pbc,2, function(rw){sum(is.na(rw))})
st.t <- apply(pbc.trial,2, function(rw){sum(is.na(rw))})

st <- data.frame(cbind(full=st, trial=st.t))

st <- st[which(st$full>0),]
rws <- seq(1, (nrow(st)), by = 2)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

print(xtable(st, 
             caption = "PBC missing values", 
             label = "T:missing", 
             digits = 3), 
      size = 'footnotesize', # fontsize
      booktabs = TRUE, 
      add.to.row = list(pos = as.list(rws), command = col), 
      command =  c('\\toprule' , 
                   '\\midrule' , 
                   '\\bottomrule ')
      )
@

There does appear to be a large amount of missing data in some variables of the \code{pbc} data set, indicated with dark grey bars in Figure~\ref{fig:categoricalEDA}, and rug marks in Figure~\ref{fig:continuousEDA}. Table~\ref{T:missing} details the number of missing values in each variable of the \code{pbc} data set. The \code{full} columns details the full data set, though there are \Sexpr{st["treatment", "full"]} patients that were not randomized into the trial. If we remove those observations, most of the missing values are also removed. We focus on the \Sexpr{nrow(pbc.trial)} observations from the clinical trial for the remainder of this document. We will return to handling missing values in Section~\ref{S:imputation}.


\subsection[Model Summary]{\cite{fleming:1991} model summary}
Before turning to the random forest modeling, we conclude the data set investigation by a summary of~\cite{fleming:1991} results from Chapter 4.4. We start by generating Kaplan--Meier (KM) survival estimates comparing the treatment groups of DPCA and placebo. We use the \pkg{ggRandomForests} \code{gg_survival} function to generate these estimates from the data set. 

<<gg_survival, echo=TRUE>>=
# Include only the randomized patients.
pbc.trial <- pbc[-which(is.na(pbc$treatment)),]

# Create the gg_survival object
gg_dta <- gg_survival(interval="years",
                      censor="status", 
                      strat="treatment", 
                      data=pbc.trial, conf.int=.95)
@

The code block first reduces the \code{pbc.trial} data set to only include observations from the clinical trial. The \pkg{ggRandomForests} package is designed to use a two step process in figure generation. The first step is data generation, the \code{gg_dta} object is a \code{gg_survival} data object. The \code{gg_survival} function uses the \code{data} set, the follow up \code{interval}, \code{censor} indicator and an optional grouping argument (\code{strat}). By default \code{gg_survival} also calculates $95\%$ confidence band, which we can control with the \code{conf.int} argument.

In the figure generation step, we use the \pkg{ggRandomForests} S3 plot routine \code{plot.gg_survival} as shown in the following code block. The plot function uses the data object to plot the survival estimate curves for each group and corresponding confidence interval ribbons. We have used additional \pkg{ggplot2} commands to modify the axis and legend labels (\code{labs}), the legend location (\code{theme}) and control the plot range of the y-axis (\code{coord_cartesian}) for this figure. Figure~\ref{fig:plot_gg_survival} is analogous to~\cite{fleming:1991} Figure 4.4.1 showing there is little difference between the treatment and control groups. 

<<plot_gg_survival, fig.cap="Kaplan--Meier pbc data survival estimates comparing the treatment with placebo. Mean survival with shaded 95\\% condfidence band.", echo=TRUE>>=
plot(gg_dta) +
  labs(y="Survival Probability", x="Observation Time (years)", 
       color="Treatment", fill="Treatment")+
  theme(legend.position=c(.2,.2))+
  coord_cartesian(ylim=c(0,1.01))
@

In Chapter 4,~\cite{fleming:1991} use partial likelihood methods to build a linear model with log transformations on some variables. The final, biologically reasonable model is detailed in Table~\ref{T:FHmodel} for later comparison with our random forest model results.

<<xtab, results="asis">>=
fleming.table <- data.frame(matrix(ncol=3, nrow=5))
rownames(fleming.table) <- 
  c("Age", "log(Albumin)", "log(Bilirubin", "Edema", "log(Prothrombin Time)")
colnames(fleming.table) <- c("Coef.", "Std. Err.", "Z stat.")
fleming.table[,1] <- c(0.0333, -3.0553,0.8792, 0.7847, 3.0157) 
fleming.table[,2] <- c(0.00866, 0.72408,0.09873,0.29913,1.02380) 
fleming.table[,3] <- c(3.84,-4.22,8.9,2.62,2.95) 

rws <- seq(1, (nrow(fleming.table)), by = 2)
col <- rep("\\rowcolor[gray]{0.95}", length(rws))

print(xtable(fleming.table, 
             caption = "Regression model with log transformations of continuous variables, 312 randomized cases with PBC.", 
             label = "T:FHmodel", 
             digits = 4), 
      size = 'footnotesize', # fontsize
      booktabs = TRUE, 
      add.to.row = list(pos = as.list(rws), command = col), 
      command =  c('\\toprule' , 
                   '\\midrule' , 
                   '\\bottomrule ')
      )
@

In Figure~\ref{fig:plot_gg_survival}, we demonstrated grouping on a categorical variable (\code{treatment}). However, with the exception of \code{edema}, all variables in the~\cite{fleming:1991} model are continuous. To demonstrate plotting grouped survival on a continuous variable, we examine KM estimates of survival by stratified bilirubin grouping from~\cite{fleming:1991} Figure 4.4.2. 

The following code block duplicates the \code{pbc.trial} data for this exercise. We set up the \code{bili} groups using the \code{cut} function with intervals matching the reference figure. For this example we combine the data generation and plot steps into a single line of code. The \code{error} argument of the \code{plot.gg_survival} is used to control display of the confidence bands. We suppress the intervals for this figure with \code{error="none"} and again modify the plot display with \pkg{ggplot2} commands as before to generate Figure~\ref{fig:gg_survival-bili}.

<<gg_survival-bili, fig.cap="Kaplan--Meier pbc data survival estimates comparing Bilirubin measures. Groups defined in~\\cite{fleming:1991}.", echo=TRUE, fig.width=5.5>>=
# Duplicate the trial data
pbc.bili <- pbc.trial

# Group by bilirubin values 
pbc.bili$bili_grp <- cut(pbc.trial$bili, 
                         breaks=c(0,.8,1.3,3.4, max(pbc.trial$bili)))

# plot the gg_survival object directly
plot(gg_survival(interval="years",censor="status", 
                 strat="bili_grp", data=pbc.bili ),
     error="none") +
  labs(y="Survival Probability", 
       x="Observation Time (years)", 
       color="Bilirubin")
@


\section{Random Survival Forest}\label{S:rfsrcGrow}
A Random Forest~\citep{Breiman:2001} is grown by \emph{bagging}~\citep{Breiman:1996} a collection of \emph{classification and regression trees} (CART)~\citep{cart:1984}. The method uses a set of $B$ \emph{bootstrap}~\citep{bootstrap:1994} samples, growing an independent tree model on each sub-sample of the population. Each tree is grown by recursively partitioning the population based on optimization of a \emph{split rule} over the $p$-dimensional covariate space. At each split, a subset of $m \le p$ candidate variables are tested for the split rule optimization, dividing each node into two daughter nodes. Each daughter node is then split again until the process reaches the \emph{stopping criteria} of either \emph{node purity} or \emph{node member size}, which defines the set of \emph{terminal (unsplit) nodes} for the tree. In regression trees, node impurity is measured by mean squared error, whereas in classification problems, the Gini index is used~\citep{Friedman:2000} . 

Random Forests sort each training set observation into one unique terminal node per tree. Tree estimates for each observation are constructed at each terminal node, among the terminal node members. The Random Forest estimate for each observation is then calculated by aggregating, averaging (regression) or votes (classification), the terminal node results across the collection of $B$ trees.

Random Forests for survival~\citep{Ishwaran:2007, Ishwaran:2008} (RF-S) are an extension of~\cite{Breiman:2001} Random Forests for right censored time to event data. A forest of survival trees is grown using a log-rank splitting rule to select the optimal candidate variables. Survival estimate for each observation are constructed with a Kaplan--Meier (KM) estimator within each terminal node, at each event time. 

Random Forests for survival adaptively discover nonlinear effects and interactions and are fully nonparametric. Averaging over trees, with randomization while growing a tree, enables RF-S to approximate complex survival functions, including non-proportional hazards, while maintaining low prediction error. \cite{Ishwaran:2010a} showed that RF-S is uniformly consistent and that survival forests have a uniform approximating property in finite-sample settings, a property not possessed by individual survival trees.

The \pkg{randomForestSRC} \code{rfsrc} function call grows the forest, determining the type of forest by the response supplied in the \code{formula} argument. In the following code block, we grow a random forest for survival, by passing a survival (\code{Surv}) object to the forest. The forest uses all remaining variables in the \code{pbc.trial} data set to generate survival estimates. 

<<rfsrc, echo = TRUE, eval = FALSE>>= 
rfsrc_pbc <- rfsrc(Surv(years, status) ~ ., 
                   data = pbc.trial, 
                   nsplit = 10, 
                   na.action = "na.impute")
rfsrc_pbc
@

<<read-forest, echo = FALSE, results = FALSE>>= 
# in reality, we use data caching to make vignette 
# compilation quicker. The rfsrc_pbc forest is stored
# as a ggRandomForests data sets
#
# This code block produces the R output from the 
# rfsrc grow block above. We set the chunk argument 
# "echo=FALSE" above so this code does not show up 
# in the manuscript.
data(rfsrc_pbc, package="ggRandomForests")
rfsrc_pbc
@

The \code{print.rfsrc} function returns information on how the random forest was grown. Here the \code{family="surv"} forest has \code{ntree=1000} trees (the default \code{ntree} argument). We used \code{nsplit=10} random split points to select random split rule, instead of an optimization on each variable at each split for performance reasons. 

\subsection{Imputation}\label{S:imputation}
The \pkg{randomForestSRC} package does missing value imputation internally in the \code{rfsrc} grow call using a modification of the missing data algorithm of~\cite{Ishwaran:2008}. 

Prior to splitting each node, missing data for the candidate variables are imputed by randomly drawing values from non-missing values also within the node. The purpose of the imputation step is to observations to be sorted into daughter nodes when the split occurs on a variable with missing data, and this imputed value. The split-statistic is calculated on the non-imputed values only. Following a node split, imputed data are reset to missing and the process is repeated until terminal nodes are reached. 

Missing data is then imputed using OOB non-missing terminal node data. For integer valued variables and censoring indicators, imputation uses a maximal class rule, whereas continuous variables and survival time use a mean rule.

The proximity matrix from the randomForest is used to update the imputation of the NAs. For continuous predictors, the imputed value is the weighted average of the non-missing obervations, where the weights are the proximities. For categorical predictors, the imputed value is the category with the largest average proximity. This process is iterated iter times.

\subsection{Generalization error}

One advantage of Random Forests is a built in generalization error estimate. Each bootstrap sample selects approximately $63.2\%$ of the population on average. The remaining $36.8\%$ of observations, the Out-of-Bag~\citep{BreimanOOB:1996e} (OOB) sample, can be used as a hold out test set for each tree. An OOB prediction error estimate can be calculated for each observation by predicting the response over the set of trees which were NOT trained with that particular observation. Out-of-Bag prediction error estimates have been shown to be nearly identical to $n$--fold cross validation estimates~\citep{StatisticalLearning:2009}. This feature of Random Forests allows us to obtain both model fit and validation in one pass of the algorithm.

<<errorPlot, fig.cap = "Random forest prediction error estimates as a function of the number of trees in the forest.">>= 
ggerr <- gg_error(rfsrc_pbc)
plot(ggerr)+
  coord_cartesian(ylim=c(.09,.31))
@

Figure~\ref{fig:rfsrc-plot} shows the predicted survival from an RF-S model, where censored device prediction is colored in blue, and devices experiencing an event are colored in red. 
<<rfsrc-plot, fig.cap = "Random forest predicted survival. Blue lines correspond to censored observations, red lines correspond to patients who experienced the event (death).">>= 
gg_dta <- gg_rfsrc(rfsrc_pbc)
ggRFsrc <- plot(gg_dta, alpha=.2) + 
  scale_color_manual(values = strCol) + 
  theme(legend.position = "none") + 
  labs(y = "Survival Probability", x = "time (years)")+
  coord_cartesian(ylim=c(-.01,1.01))
ggRFsrc
@

<<rfsrc-plot-split, fig.cap = "Random forest predicted survival. Split on death event, black loess curve indicates the mean survival estimate within each group.">>= 
ggRFsrc+
  geom_smooth(aes(by=cens), color="black")+
  facet_wrap(~cens, ncol=1)
@

<<rfsrc-mean, fig.cap = "Mean value random forest predicted survival with shaded 95\\% confidence band.">>= 
gg_src <- plot.gg_rfsrc(rfsrc_pbc,   level=.95) + 
  scale_color_manual(values = strCol) + 
  theme(legend.position = "none") + 
  labs(y = "Survival Probability", x = "time (years)")+
  coord_cartesian(ylim=c(-.01,1.01))
gg_src
@

<<rfsrc-mean2, fig.cap = "Mean value random forest predicted survival with shaded 95\\% confidence band.">>= 
gg_src <- plot.gg_rfsrc(rfsrc_pbc, by="treatment", level=.95) + 
  scale_color_manual(values = strCol) + 
  theme(legend.position = "none") + 
  labs(y = "Survival Probability", x = "time (years)")+
  coord_cartesian(ylim=c(-.01,1.01))
gg_src
@



\section{Variable Selection}\label{S:variableselection}
Unlike in the linear model settings, Random Forests does not require explicitly specify the functional form of the covariates to the response. Instead, we ascertain which variables contribute to the Random Forest estimates by querying the forest for variable usage. 

\subsection{Variable Importance}\label{S:vimp}
Unlike in the linear model settings, Random Forests does not require explicitly specify the functional form of the covariates to the response. Instead, we ascertain which variables contribute to the Random Forest estimates by querying the forest for variable usage. 

Variable importance (VIMP) was originally defined in CART using a measure involving surrogate variables (see Chapter 5 of~\cite{cart:1984}). The most popular VIMP method to date, adopts a prediction error approach involving "noising-up" a variable. VIMP for a variable $x_v$ is the difference between prediction error when $x_v$ is noised up by permuting its value randomly, compared to prediction error under the original predictor~\citep{Breiman:2001, liaw:2002, Ishwaran:2007, Ishwaran:2008}.

Since VIMP is the absolute difference between prediction errors before and after permutation, a large VIMP value indicates that misspecification of that variable detracts from the predictive accuracy of the forest. VIMP close to zero indicates the variable contributes nothing to predictive accuracy, and negative values indicate the predictive accuracy improves when the variable is mispecified. In the later case, we assume noise is more informative than the variable. As such, we ignore variables with negative and near zero values of VIMP, relying on large positive values to indicate that the predictive power of the forest is dependent on those variables. 

In Figure~\ref{fig:rf-vimp}, we plot VIMP measures for each of the variables used to grow the forest estimates of Figure~\ref{fig:rfsrc-plot}. Variables are shown in VIMP rank order, largest (op\_yr) at the top, to smallest (iv\_lospr) at the bottom. In this case, we would focus attention on the top three variables (op\_yr (surgical date), ld and devno).
<<rf-vimp, echo = TRUE, fig.cap = "Random forest variable Importance (VIMP). Blue bars indicate important variables (positive VIMP), red indicates noise variables (negative VIMP).", fig.width=5>>= 
plot.gg_vimp(rfsrc_pbc, lbls = st.labs) + 
  theme(legend.position = c(.8,.2))+
  labs(fill="VIMP > 0")+
  scale_fill_brewer(palette="Set1")
@

\subsection{Minimal Depth}\label{S:minimalDepth}
In VIMP, prognostic risk factors are determined by inspection of the forest, ranking the most important variables according to impact on predictive ability of the forest. An alternative method recognizes that most important variables for prediction are those that most frequently split nodes nearest to the trunks of the trees (ie, at the root node) since they partition the largest portions of the population. 

Node levels are numbered based on their relative distance to the trunk of the tree (ie. 0, 1, 2). A measure of important risk factors is determined by averaging the depth of first split for each variable over all trees within the forest. Lower values of this measure indicate variables that split larger groups of patients. 

The maximal subtree for a variable $x$ is the largest subtree whose root node splits on $x$. Thus, all parent nodes of $x$'s maximal subtree have nodes that split on variables other than $x$. The largest maximal subtree possible is the root node. In general, however, there can be more than one maximal subtree for a variable. A maximal subtree may also not exist if there are no splits on the variable. The minimal depth of a maximal subtree (the first order depth) measures predictiveness of a variable $x$. It equals the shortest distance (the depth) from the root node to the parent node of the maximal subtree (zero is the smallest value possible). The smaller the minimal depth, the more impact $x$ has on prediction. The mean of the minimal depth distribution is used as the threshold value for deciding whether a variable's minimal depth value is small enough for the variable to be classified as strong. 

The minimal depth plot of Figure~\ref{fig:mindepth} is similar to the VIMP plot in Figure~\ref{fig:rf-vimp}, ranking variables from most important at the top (minimal depth measure), to least at the bottom (maximal minimal depth). Since the VIMP and Minimal Depth measures use different criteria, we expect the variable ranking to be slightly different. In this case, minimal depth indicates seven most important variables (op\_yr (surgical date), age, ld, ht, wt, iv\_lospr (length of stay) and inr). The vertical dashed line indicates the minimal depth threshold where smaller minimal depth values indicate higher importance and larger indicate lower importance.


<<mindepth-view, eval = FALSE, echo = TRUE>>= 
varsel_pbc <- var.select(rfsrc_pbc)
ggMindepth <- gg_minimal_depth(varsel_pbc, lbls = st.labs)
print(ggMindepth)
@

<<mindepth-load>>= 
data(varsel_pbc, package="ggRandomForests")
ggMindepth <- gg_minimal_depth(varsel_pbc)
ggMindepth
@

<<mindepth-plot, echo=TRUE, fig.cap = "Minimal Depth variable selection. Low minimal depth indicates important variables. The dashed line is the threshold of maximum value for variable selection.", fig.width=5>>= 
plot(ggMindepth, lbls = st.labs)
@

<<depthVimp, fig.cap="Comparing Minimal Depth and Vimp rankings. Points on the red dashed line are ranked equivalently, points below have higher VIMP, those above have higher minimal depth ranking. Variables are colored by the sign of the VIMP measure.", fig.width=6>>=
gg.mv <- gg_minimal_vimp(varsel_pbc)
plot(gg.mv, lbls = st.labs)+
  scale_y_continuous(breaks=seq(0,20,2))
@

\section{Variable Dependence}\label{S:dependence}
Once we have an idea of which variables contribute to the predictive accuracy of the forest, it is useful to get some idea of form of this contribution. We use graphical methods to show the predicted response given dependence on covariates. We can plot the marginal effect of an covariate on the class probability (classification), response (regression), mortality (survival), or the expected years lost (competing risk) for a RF analysis. We plot the ensemble predicted value on the vertical axis and covariates along the horizontal axis.

\subsection{Marginal Dependence}\label{S:variabledependence}
\emph{Marginal variable dependence} plots the predicted response as a function of the covariate, showing each subject as a point on the plot. For classification and regression, this is straight forward predicting the response. In survival settings, we must account for the additional dimension of time. In this case, we plot the response at a specific time point of interest, for example survival at three months shown by the vertical dashed line in Figure~\ref{fig:rfsrc-plot3Mnth}. We take the predicted value of each curve at that time, and plot that against the covariate value for that observations, shown in Figure~\ref{fig:variable-plot}. Again censored cases are shown in blue circles, events are indicated by the red "x" symbols. Each predicted point is dependent on the full combination of all other covariates, not only on the covariate displayed in the dependence plot, so interpretation of these variable dependence plots can only be in general terms. The smooth loess line~\citep{cleveland:1981, cleveland:1988} indicates the trend of the prediction over surgical date progression.

<<rfsrc-plot3Mnth, echo = TRUE, fig.cap = "Random forest OOB predicted patient survival. Red curves correspond to patients which have died, blue corresponds to alive (or censored) cases. Vertical dashed lines indicate the 1 and 3 year survival estimates.">>= 
ggRFsrc + 
  geom_vline(aes(xintercept = c(1, 3)), linetype = "dashed") + 
  coord_cartesian(x = c(0, 4))
@

<<variable-plotbili, echo = TRUE, fig.cap = "Bilirubin variable dependence at 1 and 3 years. Individual cases are marked with blue circles (alive or censored) and red xs (dead). Loess smooth curve with shaded 95\\% confidence band indicates the survival trend with increasing bilirubin.", fig.height = 4>>= 
xvar <- varsel_pbc$topvars[1:7]

ggrf <- gg_variable(rfsrc_pbc, time = c(1, 3), 
                    time.labels = c("1 Year", "3 Years"))

plot(ggrf, xvar = xvar[1], se=.95, alpha=.3) + 
  labs(y = "Survival") + 
  theme(legend.position = "none") + 
  scale_color_manual(values = strCol, labels = event.labels) + 
  scale_shape_manual(values = event.marks, labels = event.labels)
@

<<variable-plotCombines, echo = TRUE, fig.cap = "Variable dependence plots at 1 and 3 years for continuous variables age, albumin, copper and prothrombin. Individual cases are marked with blue circles (alive or censored) and red xs (dead). Loess smooth curve indicates the survival trend with increasing variable value.", fig.width = 7, fig.height = 4>>= 
plot(ggrf, xvar = xvar[-c(1,7)], panel = TRUE, 
     se=FALSE, alpha=.3, 
     method="glm", formula=y~poly(x,2)) + 
  labs(y = "Survival") + 
  theme(legend.position = "none") + 
  scale_color_manual(values = strCol, labels = event.labels) + 
  scale_shape_manual(values = event.marks, labels = event.labels)+
  coord_cartesian(y=c(-.1,1.02))
@

<<variable-plotEdema, echo = TRUE, fig.cap = "Variable dependence plots at 1 and 3 years for categorical edema variable. Individual cases are marked with blue circles (alive or censored) and red xs (dead). Boxes indicate distributional properties of observations in each group.">>= 
plot(ggrf, xvar = "edema", notch=TRUE, alpha=.5) + 
  labs(y = "Survival") + 
  theme(legend.position = "none") + 
  scale_color_manual(values = strCol, labels = event.labels) + 
  scale_shape_manual(values = event.marks, labels = event.labels)+
  coord_cartesian(y=c(-.1,1.02))
@
\subsection{Partial Dependence}\label{S:partialdependence}

\emph{Partial dependence plots} are a risk adjusted alternative to marginal variable dependence. Partial plots are generated by integrating out the effects of variables beside the covariate of interest. The figures are constructed by selecting points evenly spaced along the distribution of the X variable. For each of these values (X = x), we calculate the average Random Forest prediction over all other covariates in X by \eqref{E:partial}.
\begin{equation}
\tilde{f}(x) = \frac{1}{n} \sum_{i = 1}^n \hat{f}(x, x_{i, o}), 
\label{E:partial}
\end{equation}
where $\hat{f}$ is the predicted response from the random forest and $x_{i, o}$ is the value for all other covariates other than $X = x$ for the observation $i$~\citep{Friedman:2000}. Partial dependence plots in time to event settings are shown at specific time points, similar to variable dependence.

Figure~\ref{fig:pbc-partial-bili} shows the partial dependence of three month survival on bilirubin. 

<<pbc-partial, echo=TRUE, eval=FALSE>>= 
# Calculate the 1, 3 and 5 year partial dependence
partial_pbc <- lapply(c(1,3,5), function(tm){
  plot.variable(rfsrc_pbc, surv.type = "surv", 
                time = tm, 
                xvar.names = xvar, partial = TRUE, 
                show.plots = FALSE)
  })
@

<<pbc-partial-load>>= 
data("partial_pbc", package="ggRandomForests")
@


<<pbc-partial-bili, echo = TRUE, fig.cap = "Partial dependence plot of (risk adjusted) predicted survival probability as a function of serum bilirubin at 1 year (red circle) and 3 years (blue triangle). Loess smooth curves indicates the trend.">>= 
# Convert all partial plots to gg_partial objects
gg_dta <- lapply(partial_pbc, gg_partial)

# Combine the objects to get multiple time curves 
# along variables on a single figure.
pbc_ggpart <- combine.gg_partial(gg_dta[[1]],gg_dta[[2]], 
                                 lbls = c("1 Year", "3 Years"))

plot(pbc_ggpart[["bili"]], se = FALSE) + 
  theme(legend.position = c(.8, .5)) + 
  labs(y = "Survival", 
       x = st.labs["bili"],
       color="Time", shape="Time")+
  scale_color_brewer(palette="Set1")
@

Non-proportional hazards are evident in Figure~\ref{fig:pbc-partial-bili}.

<<pbc-partial-panel, echo = TRUE, fig.cap = "Partial dependence plot of (risk adjusted) predicted survival probability as a function continuous variables prothrombin time, albumin, age and urin copper at 1 year (red circle) and 3 years (blue triangle).", fig.width = 7, fig.height = 4, eveal=FALSE>>= 
# Create a temporary holder and remove the bilirubin and edema data
ggpart <- pbc_ggpart
ggpart$edema <- NULL

# Panel plot the remainder.
plot(ggpart, se = FALSE, panel = TRUE) + 
  labs(x = "", y = "Survival",color="Time", shape="Time") +
  scale_color_brewer(palette="Set1")
@

<<pbc-partial-edema, echo = TRUE, fig.cap = "Partial dependence plot of (risk adjusted) predicted survival probability as a function of edema (categorical variable) at 1 year (red circle) and 3 years (blue triangle). Points indicate risk adjusted prediction for all patients within each edema group. Box plots indicate distributional properties within each group.", eval=FALSE>>= 
plot(pbc_ggpart$edema, notch=TRUE, alpha=.3, outlier.shape = NA) + 
  labs(x = "Edema", y = "Survival (%)")+
  scale_color_brewer(palette="Set1")+
  facet_grid(~group)+
  theme(legend.position="none")
@

\section{Variable Interactions}\label{S:interactions}
Using the different variable dependence measures, we can calculate pairwise interactions for any pair of variables. Minimal depth is calculated as the maximal subtree using the normalized minimal depth of variable $i$ relative to the root node (normalized with respect to the size of the tree). For interactions, we calculate the maximal subtree interaction measure as the normalized minimal depth of a variable $j$ with respect to the maximal subtree for variable $i$ (normalized with respect to the size of $i$'s maximal subtree)~\citep{Ishwaran:2010,Ishwaran:2011}.

<<interaction-show, echo = TRUE, eval = FALSE>>= 
interaction_pbc <- find.interaction(rfsrc_pbc)

ggint <- gg_interaction(interaction_pbc)
plot(ggint, xvar = "bili") + 
  labs(y = "Interactive Minimal Depth")
@

<<interaction, fig.cap = "Minimal depth variable interaction with bilirubin (marked with red cross). Higher values indicate lower interactivity with target variable.">>= 
#pDat.int <- find.interaction(rfsrc_pbc)
data("interaction_pbc", package="ggRandomForests")

plot(gg_interaction(interaction_pbc), xvar = "bili") + 
  labs(y = "Interactive Minimal Depth")
@

Measuring interactions with minimal depth results a $p \times p$ matrix of interaction measures, with smaller diagonal measures relative to the root node, and off diagonal measures of pairwise interaction. We expect the covariate with smallest minimal depth to have the highest interactive depth measures, so viewed alone may not be as informative as looking at other interactive depth plots. Figure~\ref{fig:interactionPanel} combines the remaining top ranked minimal depth measures for comparison.
<<interactionPanel, echo = TRUE, fig.cap = "Minimal depth variable interaction panel with prothrombin time, albumin, urine copper and edema. Higher values indicate lower interactivity with target variable.", fig.width = 7, fig.height = 4>>= 
plot(gg_interaction(interaction_pbc), xvar = xvar[-1]) + 
  labs(y = "Interactive Minimal Depth") + 
  theme(legend.position = "none")
@

\section{Conditional Dependence Plots}\label{S:coplots}

By plotting the resulting interaction measures for each variable (Figure~\ref{fig:interaction}), we can detect the "most interactive" pairs, and develop conditional plots~\cite{chambers:1992, cleveland:1993}. These plots are similar to stratified results, arranged in a set of panels by the interactive variable of interest. 

Interactions with categorical data are more straight forward, and can be generated directly from variable dependence plots. Recall the 1 year variable dependence for Billirubin, shown in Figure~\ref{fig:var_dep}. 
<<var_dep, echo = TRUE, fig.cap = "Variable dependence plot. Survival at 1 year against bilirubin. Individual cases are marked with blue circles (alive or censored) and red x (dead). Loess smooth curve indicates the trend as bilirubin  increases.">>= 
ggvar <- gg_variable(rfsrc_pbc, time = 1)
ggvar$stage <- paste("stage=", ggvar$stage, sep="")

var_dep <- plot(ggvar, xvar = "bili", smooth = TRUE, 
                method = "loess", span=1.5,alpha = .5, se = FALSE) + 
  labs(y = "Survival", 
       x = st.labs["bili"]) + 
  theme(legend.position = "none") + 
  scale_color_manual(values = strCol, labels = event.labels) + 
  scale_shape_manual(values = event.marks, labels = event.labels)

show(var_dep)
@

We can view the conditional dependence of survival against bilirubin, versus other categorical covariates, say treatment (binary) and stage (categorical), by adding a facet argument.
<<coplot_bilirubin, echo = TRUE, fig.cap = "Variable dependence coplot. Survival at 1 year against bilirubin, stratified by treatment and histological stage.", fig.width = 7, fig.height = 4>>= 
var_dep + 
  facet_grid(treatment~stage)
@

Interactions with continuous variables requires stratification at some level.

\subsection{Albumin}
<<albumin-coplot, fig.cap="Variable dependence coplot. Survival at 1 year against bilirubin, stratified by continous variable albumin.", fig.width = 7, fig.height = 4, echo=TRUE>>=
# albumin_grp <- cut(rfsrc_pbc$xvar$albumin, breaks=c(0,seq(3,3.5,.5),5))
albumin_grp <- cut(rfsrc_pbc$xvar$albumin, breaks=6)
ggvar$albumin_grp <- paste("albumin=",albumin_grp, sep="")

var_dep <- plot(ggvar, xvar = "bili", smooth = TRUE, 
                method = "loess", span=1.5,alpha = .5, se = FALSE) + 
  labs(y = "Survival", x = st.labs["bili"]) + 
  theme(legend.position = "none") + 
  scale_color_manual(values = strCol, labels = event.labels) + 
  scale_shape_manual(values = event.marks, labels = event.labels)+ 
  facet_wrap(~albumin_grp)

var_dep
@

<<build-bili-albumin, eval=FALSE>>=
partial_coplot_pbc <- gg_partial_coplot(rfsrc_pbc, xvar="bili", 
                                         groups=albumin_grp, 
                                         surv_type="surv", 
                                         time=1, 
                                         show.plots=FALSE)
@

<<bili-albumin, fig.cap="Partial (risk adjusted) variable dependence coplot. Survival at 1 year against bilirubin, stratified by albumin groups. Points mark risk adjusted estimates, loess smooth indicates predicted trend within each age group as a function of bilirubin.", fig.width = 7, fig.height = 4, echo=TRUE>>=
data(partial_coplot_pbc, package="ggRandomForests")
ggpl <- ggplot(partial_coplot_pbc, aes(x=bili, y=yhat, 
                                          shape=group, 
                                          color=group))+
  geom_point()+geom_smooth(se=FALSE)+
  labs(x=st.labs["bili"], y="Survival 1 year", 
       color="Albumin", shape="Albumin")+
  scale_color_brewer(palette="Set1")
ggpl
@

\section{Conclusion}

\appendix

%\singlespacing
\bibliography{ggRandomForests}

\end{document}


---


\subsection{ggRandomForests}
The \pkg{randomForestSRC} package is a mature analysis and research random forest implementation under rapid development. The package includes diagnostic and post processing functions for analysis and visualizations of randomForest model properties. However, in our research we frequently found it difficult to manipulate the standard figures directly produced with the \pkg{randomForestSRC} package. 

In order to simplify these manipulations, we developed the \pkg{ggRandomForests} package. We attempted to follow two design principles in this development:
\begin{itemize}
\item Model/View separation: The package originally designed to generating \pkg{ggplot2}~\cite{Wickham:2009} figures for random forest objects. However, some users would prefer to use other graphing methods within \proglang{R} or outside of it. To help users, we separate the data generation and the figure generation into two separate operations. 

\item Modular: We strive to create a modular design by following the \emph{do one thing well} philosphy. Each function operates on one \pkg{randomForestSRC} object to create only one data object or figure type.
\end{itemize}
